{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword / Keyphrase extraction\n",
    "We are looking for search terms that we can use to find Coronavirus pandemic related search terms. \n",
    "\n",
    "### How to get a good list of search terms?\n",
    "- tried 3 different kw extraction tools. Pytextrank and RAKE seem best at finding relevant ngrams.\n",
    "- A human will have to check the resultant lists to pick out the most useful keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, read in the data\n",
    "This is the semantic Scholar CORD data dump which was munged into a dataframe in a previous notebook.\n",
    "https://pages.semanticscholar.org/coronavirus-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34185, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/s2_cr_data.csv', dtype=str)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sha', 'source_x', 'title', 'doi', 'pmcid', 'pubmed_id', 'license',\n",
       "       'abstract', 'publish_time', 'authors', 'journal',\n",
       "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
       "       'full_text_file', 'tiabs', 'journal-short', 'pubdate', 'issns',\n",
       "       'publisher', 'cr_dates', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "We've already done some exploration of the data in a previous notebook, but we can check some things here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000    7821\n",
       "2019    2596\n",
       "2018    2314\n",
       "2017    2037\n",
       "2016    2035\n",
       "2015    1882\n",
       "2020    1760\n",
       "2014    1663\n",
       "2013    1516\n",
       "2012    1305\n",
       "2011    1212\n",
       "2009    1051\n",
       "2010    1040\n",
       "2008     921\n",
       "2007     765\n",
       "2006     723\n",
       "2005     642\n",
       "2004     585\n",
       "2003     253\n",
       "1992     129\n",
       "1991     129\n",
       "1995     125\n",
       "1993     118\n",
       "1994     115\n",
       "1990     105\n",
       "1998      99\n",
       "1989      99\n",
       "2002      98\n",
       "1997      98\n",
       "1996      97\n",
       "1988      96\n",
       "1999      96\n",
       "2000      90\n",
       "1987      88\n",
       "2001      79\n",
       "1986      78\n",
       "1985      57\n",
       "1984      46\n",
       "1983      43\n",
       "1982      31\n",
       "1981      30\n",
       "1977      19\n",
       "1979      19\n",
       "1980      19\n",
       "1978      16\n",
       "1976      10\n",
       "1973       7\n",
       "1975       7\n",
       "1970       5\n",
       "1972       4\n",
       "1974       3\n",
       "['20       3\n",
       "1957       1\n",
       "1963       1\n",
       "1971       1\n",
       "1967       1\n",
       "1955       1\n",
       "1965       1\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what time-frame does this cover?\n",
    "# consider limiting to recent years\n",
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24567, 22)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit years - only recent stuff is likely to be relevant (?)\n",
    "df=df[df['year'].isin(set([str(x) for x in range(2000,2021)]))]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What keywords can we find with SpaCy?\n",
    "Adapted from: https://medium.com/better-programming/extract-keywords-using-spacy-in-python-4a8415478fbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_lg\n",
    "# !python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "                \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotwords = []\n",
    "\n",
    "for abstract in df['tiabs']:\n",
    "    abstract = str(abstract)\n",
    "    if len(abstract.split())>5:\n",
    "        hotwords.extend(get_hotwords(abstract))\n",
    "len(hotwords)    \n",
    "#     hashtags = [('#' + x[0]) for x in Counter(get_hotwords).most_common(5)]\n",
    "# print(' '.join(hashtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_hotwords = [x for x in Counter(hotwords).most_common(30)]\n",
    "common_hotwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdf = pd.DataFrame(common_hotwords, columns = ['kw','count'])\n",
    "hotdf['algo'] = 'hotwords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly, this is giving us single words rather than phrases. A lot of these are too broad to discriminate COVID-19-related research from other research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytextrank\n",
    "This is a different model that we can also use with SpaCy for finding keywords and keyphrases. \n",
    "Adapted from: https://pypi.org/project/pytextrank/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytextrank\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "tr = pytextrank.TextRank()\n",
    "nlp.add_pipe(tr.PipelineComponent, name='textrank', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = []\n",
    "for abstract in df['tiabs']:\n",
    "    doc = nlp(abstract)\n",
    "    keyphrases.extend([(p.text,i) for i,p in enumerate(doc._.phrases)])\n",
    "pytr = pd.DataFrame((keyphrases), columns = ['kw','rank'])\n",
    "pytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytr = pytr[pytr['rank']<5].groupby('kw').count().sort_values('rank', ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytr.columns= ['kw','count']\n",
    "pytr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(keyphrases).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytr['algo'] = 'pytextrank'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better. We're getting a list of phrases (or ngrams) which seem quite relevant to the coronavirus outbreak. There will be some need to sort through these manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAKE - Rapid Automatic Keyword Extraction\n",
    "Adapted from: https://pypi.org/project/rake-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rake_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "rake_kws = []\n",
    "r = Rake()\n",
    "for abstract in df['tiabs']:\n",
    "    r.extract_keywords_from_text(abstract)\n",
    "    rake_kws.extend([(keyphrase,i) for i, keyphrase in enumerate(r.get_ranked_phrases())])\n",
    "rake = pd.DataFrame(rake_kws, columns = ['kw','rank'])\n",
    "rake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake[rake['rank']<=5].groupby('kw').mean().sort_values('rank').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows= Counter([x[0] for x in rake_kws if x[1]<5]).most_common(100)\n",
    "columns = ['kw','count']\n",
    "\n",
    "rakedf = pd.DataFrame(rows,columns=columns)\n",
    "rakedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rakedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rakedf['algo'] = 'RAKE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also a good list of ngrams which we can use for coronavirus searches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out to file\n",
    "Concatenate all 3 of the keyword lists we produced above into a spreadsheet and output to xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.concat([\n",
    "    pytr,\n",
    "    rakedf,\n",
    "#     hotdf  # I'm commenting this out because I don't think the keywords here were very useful\n",
    "])\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fairly small and might be ok to put in github for sharing purposes. (Large amounts of data shouldn't go in github.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_excel('output/keyword_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
