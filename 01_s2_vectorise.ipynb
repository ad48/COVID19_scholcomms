{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation (turning text into numbers)\n",
    "There are a lot of ways to turn text into numbers. Here, we will use Doc2Vec, but other algorithms do this well including BERT, LDA, LSI etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12617, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in our data\n",
    "df = pd.read_csv('data/s2_cr_data.csv', dtype=str)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process\n",
    "Different algorithms and different text corpora call for different kinds of pre-processing. What we are doing here is trying to make the text as easy as possible for the computer to 'understand' without destroying any valuable features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel, Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.utils import deaccent\n",
    "from gensim.parsing.preprocessing import strip_short, strip_punctuation, remove_stopwords, strip_multiple_whitespaces, stem_text\n",
    "from gensim.parsing import preprocess_string\n",
    "from gensim import corpora\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngramming\n",
    "We will start by building Ngrammers. These are very simple models which learn when words tend to appear together. The typical example here is 'New York', which is 2 words, but which we treat as one. Is therefore a 'bigram'. We might also be interested in 'New York City', which is 3 words that often appear together, so that's a \"trigram\".\n",
    "\n",
    "We will run 2 processes where we first search our text for bigrams and then trigrams. Essentially, it's just the same process run twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:04:37,670 : INFO : collecting all words and their counts\n",
      "2020-03-19 17:04:37,673 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training bigram detection\n",
      "0 iterations done\n",
      "1000 iterations done\n",
      "2000 iterations done\n",
      "3000 iterations done\n",
      "4000 iterations done\n",
      "5000 iterations done\n",
      "6000 iterations done\n",
      "7000 iterations done\n",
      "8000 iterations done\n",
      "9000 iterations done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:04:46,617 : INFO : PROGRESS: at sentence #10000, processed 2559767 words and 979691 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 iterations done\n",
      "11000 iterations done\n",
      "12000 iterations done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:04:48,772 : INFO : collected 1175333 word types from a corpus of 3193208 words (unigram + bigrams) and 12617 sentences\n",
      "2020-03-19 17:04:48,773 : INFO : using 1175333 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10, max_vocab_size=40000000>\n",
      "2020-03-19 17:04:48,773 : INFO : source_vocab length 1175333\n",
      "2020-03-19 17:04:56,764 : INFO : Phraser built with 16470 phrasegrams\n",
      "2020-03-19 17:04:56,765 : INFO : saving Phraser object under models/bigram_d2v, separately None\n",
      "2020-03-19 17:04:56,795 : INFO : saved models/bigram_d2v\n",
      "2020-03-19 17:04:56,796 : INFO : collecting all words and their counts\n",
      "2020-03-19 17:04:56,797 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training trigram detection\n",
      "0 iterations done\n",
      "1000 iterations done\n",
      "2000 iterations done\n",
      "3000 iterations done\n",
      "4000 iterations done\n",
      "5000 iterations done\n",
      "6000 iterations done\n",
      "7000 iterations done\n",
      "8000 iterations done\n",
      "9000 iterations done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:05:08,768 : INFO : PROGRESS: at sentence #10000, processed 2192159 words and 996553 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 iterations done\n",
      "11000 iterations done\n",
      "12000 iterations done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:05:11,701 : INFO : collected 1190095 word types from a corpus of 2736622 words (unigram + bigrams) and 12617 sentences\n",
      "2020-03-19 17:05:11,701 : INFO : using 1190095 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10, max_vocab_size=40000000>\n",
      "2020-03-19 17:05:11,721 : INFO : source_vocab length 1190095\n",
      "2020-03-19 17:05:21,789 : INFO : Phraser built with 38863 phrasegrams\n",
      "2020-03-19 17:05:21,790 : INFO : saving Phraser object under models/trigram_d2v, separately None\n",
      "2020-03-19 17:05:21,852 : INFO : saved models/trigram_d2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigrams trained and saved\n"
     ]
    }
   ],
   "source": [
    "bigram_phraserpath = 'models/bigram_d2v'\n",
    "trigram_phraserpath = 'models/trigram_d2v'\n",
    "\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(),\n",
    "                    deaccent,\n",
    "                    strip_punctuation,\n",
    "                    strip_multiple_whitespaces,\n",
    "                    # strip_short, #(minsize=2),\n",
    "                    ] # stem or lemmatize?\n",
    "\n",
    "# define Iterator\n",
    "\n",
    "# retrieve each text entry\n",
    "def extract_text():\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        doi = str(row['doi'])\n",
    "        textdata = str(row['tiabs'])\n",
    "        textdata = preprocess_string(textdata, CUSTOM_FILTERS)\n",
    "        yield doi, textdata\n",
    "        if i%1000==0:\n",
    "            print(i, 'iterations done')\n",
    "\n",
    "\n",
    "# iteration 1\n",
    "print()\n",
    "print('Training bigram detection')\n",
    "documents = extract_text()\n",
    "phrases = Phrases(\n",
    "                (document[1]\n",
    "                 for document in documents),\n",
    "                    # min_count = 10,\n",
    "                    threshold = 10,\n",
    "                    common_terms = [\"of\", \"with\", \"without\",\n",
    "                                \"and\", \"or\", \"the\", \"a\"]\n",
    "                    # max_vocab_size = 1000000\n",
    "                    )\n",
    "bigram = Phraser(phrases)\n",
    "bigram.save(bigram_phraserpath)\n",
    "\n",
    "\n",
    "# iteration 2\n",
    "print()\n",
    "print('Training trigram detection')\n",
    "documents = extract_text()\n",
    "phrases = Phrases((bigram[document[1]]\n",
    "                    for document in documents),\n",
    "                    # min_count = 10,\n",
    "                    threshold = 10,\n",
    "                    # max_vocab_size = 2000000\n",
    "                    )\n",
    "trigram = Phraser(phrases)\n",
    "# save model\n",
    "trigram.save(trigram_phraserpath)\n",
    "print('trigrams trained and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:05:21,859 : INFO : loading Phrases object from models/bigram_d2v\n",
      "2020-03-19 17:05:21,879 : INFO : loaded models/bigram_d2v\n",
      "2020-03-19 17:05:21,881 : INFO : older version of Phrases loaded without corpus_word_count\n",
      "2020-03-19 17:05:21,882 : INFO : Setting it to 0, do not use it in your scoring function.\n",
      "2020-03-19 17:05:21,882 : INFO : loading Phrases object from models/trigram_d2v\n",
      "2020-03-19 17:05:21,932 : INFO : loaded models/trigram_d2v\n",
      "2020-03-19 17:05:21,937 : INFO : older version of Phrases loaded without corpus_word_count\n",
      "2020-03-19 17:05:21,937 : INFO : Setting it to 0, do not use it in your scoring function.\n"
     ]
    }
   ],
   "source": [
    "# pre process for d2v\n",
    "from gensim.utils import deaccent\n",
    "from gensim.parsing.preprocessing import strip_short, strip_punctuation, remove_stopwords, strip_multiple_whitespaces, stem_text\n",
    "from gensim.parsing import preprocess_string\n",
    "from gensim.models import Phrases\n",
    "\n",
    "\n",
    "bigram = Phrases.load(bigram_phraserpath)\n",
    "trigram = Phrases.load(trigram_phraserpath)\n",
    "\n",
    "def pre_d2v_search(s, bigram, trigram):\n",
    "    \n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(),\n",
    "                    deaccent,\n",
    "                    strip_punctuation,\n",
    "                    strip_multiple_whitespaces] \n",
    "    \n",
    "    return trigram[bigram[preprocess_string(s,filters= CUSTOM_FILTERS)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.summarization.textcleaner import get_sentences\n",
    "from gensim.utils import tokenize\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12617, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will allow us to load our data into the doc2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ADTaggedDocument(object):\n",
    "    def __iter__(self):\n",
    "        \n",
    "        for i,row in df.iterrows():\n",
    "            id_ = str(row['index'])\n",
    "#             doi = str(row['doi'])\n",
    "            text_data = str(row['tiabs'])\n",
    "            tokenized = pre_d2v_search(text_data, bigram, trigram)\n",
    "            yield TaggedDocument(tokenized, [id_])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we train the doc2vec model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:05:21,970 : INFO : collecting all words and their counts\n",
      "2020-03-19 17:05:21,975 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-03-19 17:05:34,983 : INFO : PROGRESS: at example #10000, processed 2045253 words (157240/s), 80437 word types, 10000 tags\n",
      "2020-03-19 17:05:38,159 : INFO : collected 90722 word types and 12617 unique tags from a corpus of 12617 examples and 2555041 words\n",
      "2020-03-19 17:05:38,159 : INFO : Loading a fresh vocabulary\n",
      "2020-03-19 17:05:38,209 : INFO : effective_min_count=6 retains 39021 unique words (43% of original 90722, drops 51701)\n",
      "2020-03-19 17:05:38,210 : INFO : effective_min_count=6 leaves 2458818 word corpus (96% of original 2555041, drops 96223)\n",
      "2020-03-19 17:05:38,288 : INFO : deleting the raw counts dictionary of 90722 items\n",
      "2020-03-19 17:05:38,290 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2020-03-19 17:05:38,291 : INFO : downsampling leaves estimated 1976940 word corpus (80.4% of prior 2458818)\n",
      "2020-03-19 17:05:38,367 : INFO : estimated required memory for 39021 words and 300 dimensions: 130824700 bytes\n",
      "2020-03-19 17:05:38,368 : INFO : resetting layer weights\n",
      "2020-03-19 17:05:45,416 : INFO : training model with 7 workers on 39021 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=8\n",
      "2020-03-19 17:05:46,719 : INFO : EPOCH 1 - PROGRESS: at 2.04% examples, 30283 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-19 17:05:47,778 : INFO : EPOCH 1 - PROGRESS: at 4.95% examples, 43330 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:05:48,803 : INFO : EPOCH 1 - PROGRESS: at 9.87% examples, 61992 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:05:49,815 : INFO : EPOCH 1 - PROGRESS: at 14.31% examples, 68807 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:05:50,887 : INFO : EPOCH 1 - PROGRESS: at 19.87% examples, 75146 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:05:51,891 : INFO : EPOCH 1 - PROGRESS: at 24.55% examples, 77780 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:05:52,929 : INFO : EPOCH 1 - PROGRESS: at 30.09% examples, 81485 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:05:53,963 : INFO : EPOCH 1 - PROGRESS: at 34.68% examples, 82426 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:05:55,021 : INFO : EPOCH 1 - PROGRESS: at 39.71% examples, 83756 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:05:56,060 : INFO : EPOCH 1 - PROGRESS: at 45.13% examples, 85739 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:05:57,079 : INFO : EPOCH 1 - PROGRESS: at 49.72% examples, 86151 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:05:58,151 : INFO : EPOCH 1 - PROGRESS: at 55.01% examples, 87353 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:05:59,182 : INFO : EPOCH 1 - PROGRESS: at 60.02% examples, 88074 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:00,308 : INFO : EPOCH 1 - PROGRESS: at 66.01% examples, 89210 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:01,377 : INFO : EPOCH 1 - PROGRESS: at 70.98% examples, 89502 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:02,475 : INFO : EPOCH 1 - PROGRESS: at 76.02% examples, 90058 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:06:03,568 : INFO : EPOCH 1 - PROGRESS: at 81.59% examples, 90512 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:04,703 : INFO : EPOCH 1 - PROGRESS: at 87.41% examples, 90736 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:05,734 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 94067 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:06:05,819 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:06:05,837 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:06:05,841 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:06:05,885 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:06:05,897 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:06:05,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:06:05,918 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:06:05,919 : INFO : EPOCH - 1 : training on 2555041 raw words (1989928 effective words) took 20.5s, 97111 effective words/s\n",
      "2020-03-19 17:06:07,414 : INFO : EPOCH 2 - PROGRESS: at 0.76% examples, 10541 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:08,418 : INFO : EPOCH 2 - PROGRESS: at 5.90% examples, 50143 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:09,418 : INFO : EPOCH 2 - PROGRESS: at 10.26% examples, 62072 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:10,479 : INFO : EPOCH 2 - PROGRESS: at 15.48% examples, 71364 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:11,540 : INFO : EPOCH 2 - PROGRESS: at 21.06% examples, 77123 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:12,630 : INFO : EPOCH 2 - PROGRESS: at 26.47% examples, 80708 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:13,664 : INFO : EPOCH 2 - PROGRESS: at 31.66% examples, 82875 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:14,779 : INFO : EPOCH 2 - PROGRESS: at 37.00% examples, 84587 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:15,788 : INFO : EPOCH 2 - PROGRESS: at 42.02% examples, 86083 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:16,792 : INFO : EPOCH 2 - PROGRESS: at 46.97% examples, 87371 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:06:17,914 : INFO : EPOCH 2 - PROGRESS: at 52.03% examples, 87533 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:06:18,915 : INFO : EPOCH 2 - PROGRESS: at 56.97% examples, 88475 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:19,931 : INFO : EPOCH 2 - PROGRESS: at 62.49% examples, 89716 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:06:20,946 : INFO : EPOCH 2 - PROGRESS: at 67.60% examples, 90354 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:06:21,952 : INFO : EPOCH 2 - PROGRESS: at 72.78% examples, 91419 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:06:22,963 : INFO : EPOCH 2 - PROGRESS: at 77.24% examples, 91366 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:23,970 : INFO : EPOCH 2 - PROGRESS: at 82.46% examples, 91771 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:25,017 : INFO : EPOCH 2 - PROGRESS: at 87.83% examples, 91943 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:26,037 : INFO : EPOCH 2 - PROGRESS: at 96.47% examples, 95295 words/s, in_qsize 10, out_qsize 0\n",
      "2020-03-19 17:06:26,111 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:06:26,125 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:06:26,128 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:06:26,133 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:06:26,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:06:26,193 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:06:26,197 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:06:26,198 : INFO : EPOCH - 2 : training on 2555041 raw words (1989016 effective words) took 20.3s, 98095 effective words/s\n",
      "2020-03-19 17:06:27,209 : INFO : EPOCH 3 - PROGRESS: at 2.43% examples, 46378 words/s, in_qsize 1, out_qsize 0\n",
      "2020-03-19 17:06:28,519 : INFO : EPOCH 3 - PROGRESS: at 4.91% examples, 43869 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:29,543 : INFO : EPOCH 3 - PROGRESS: at 9.87% examples, 62599 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:30,564 : INFO : EPOCH 3 - PROGRESS: at 15.09% examples, 72713 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:06:31,565 : INFO : EPOCH 3 - PROGRESS: at 19.90% examples, 76453 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:32,586 : INFO : EPOCH 3 - PROGRESS: at 24.95% examples, 79892 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:33,612 : INFO : EPOCH 3 - PROGRESS: at 30.40% examples, 83436 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:06:34,655 : INFO : EPOCH 3 - PROGRESS: at 35.05% examples, 84067 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:35,702 : INFO : EPOCH 3 - PROGRESS: at 40.51% examples, 86161 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:36,759 : INFO : EPOCH 3 - PROGRESS: at 45.89% examples, 87801 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:37,901 : INFO : EPOCH 3 - PROGRESS: at 51.28% examples, 88408 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:39,099 : INFO : EPOCH 3 - PROGRESS: at 56.95% examples, 89139 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:40,133 : INFO : EPOCH 3 - PROGRESS: at 62.09% examples, 89668 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:41,214 : INFO : EPOCH 3 - PROGRESS: at 67.60% examples, 90449 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:42,239 : INFO : EPOCH 3 - PROGRESS: at 72.78% examples, 91392 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:06:43,481 : INFO : EPOCH 3 - PROGRESS: at 78.51% examples, 91476 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:44,580 : INFO : EPOCH 3 - PROGRESS: at 84.13% examples, 91829 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:06:45,593 : INFO : EPOCH 3 - PROGRESS: at 89.26% examples, 92149 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:06:46,333 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:06:46,346 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:06:46,358 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:06:46,375 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:06:46,405 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:06:46,428 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:06:46,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:06:46,431 : INFO : EPOCH - 3 : training on 2555041 raw words (1989700 effective words) took 20.2s, 98348 effective words/s\n",
      "2020-03-19 17:06:48,220 : INFO : EPOCH 4 - PROGRESS: at 2.43% examples, 26277 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:49,349 : INFO : EPOCH 4 - PROGRESS: at 7.66% examples, 56003 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:50,378 : INFO : EPOCH 4 - PROGRESS: at 12.44% examples, 66770 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:06:51,477 : INFO : EPOCH 4 - PROGRESS: at 17.89% examples, 73713 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:06:52,626 : INFO : EPOCH 4 - PROGRESS: at 23.76% examples, 78704 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:53,640 : INFO : EPOCH 4 - PROGRESS: at 28.89% examples, 81559 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:54,699 : INFO : EPOCH 4 - PROGRESS: at 33.90% examples, 83214 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:06:55,741 : INFO : EPOCH 4 - PROGRESS: at 38.92% examples, 84648 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:56,880 : INFO : EPOCH 4 - PROGRESS: at 44.75% examples, 86527 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:57,929 : INFO : EPOCH 4 - PROGRESS: at 50.08% examples, 87990 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:06:58,929 : INFO : EPOCH 4 - PROGRESS: at 55.01% examples, 88949 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:06:59,975 : INFO : EPOCH 4 - PROGRESS: at 60.44% examples, 90035 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:07:00,979 : INFO : EPOCH 4 - PROGRESS: at 65.67% examples, 90748 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:07:02,013 : INFO : EPOCH 4 - PROGRESS: at 70.21% examples, 90661 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:03,027 : INFO : EPOCH 4 - PROGRESS: at 75.65% examples, 92065 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:07:04,060 : INFO : EPOCH 4 - PROGRESS: at 80.07% examples, 91440 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:05,082 : INFO : EPOCH 4 - PROGRESS: at 85.38% examples, 91740 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:07:06,121 : INFO : EPOCH 4 - PROGRESS: at 90.51% examples, 91949 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:06,601 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:07:06,644 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:07:06,649 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:07:06,704 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:07:06,716 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:07:06,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:07:06,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:07:06,727 : INFO : EPOCH - 4 : training on 2555041 raw words (1989812 effective words) took 20.3s, 98059 effective words/s\n",
      "2020-03-19 17:07:07,823 : INFO : EPOCH 5 - PROGRESS: at 3.19% examples, 57198 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-19 17:07:08,931 : INFO : EPOCH 5 - PROGRESS: at 8.04% examples, 77578 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-19 17:07:09,944 : INFO : EPOCH 5 - PROGRESS: at 13.16% examples, 86715 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-19 17:07:11,723 : INFO : EPOCH 5 - PROGRESS: at 18.29% examples, 75972 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:07:12,807 : INFO : EPOCH 5 - PROGRESS: at 23.00% examples, 77596 words/s, in_qsize 13, out_qsize 1\n",
      "2020-03-19 17:07:13,898 : INFO : EPOCH 5 - PROGRESS: at 28.49% examples, 80897 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:14,899 : INFO : EPOCH 5 - PROGRESS: at 33.55% examples, 83250 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:15,936 : INFO : EPOCH 5 - PROGRESS: at 38.54% examples, 84710 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:17,146 : INFO : EPOCH 5 - PROGRESS: at 44.70% examples, 86746 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:18,170 : INFO : EPOCH 5 - PROGRESS: at 49.72% examples, 87700 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:19,243 : INFO : EPOCH 5 - PROGRESS: at 54.66% examples, 88168 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:20,329 : INFO : EPOCH 5 - PROGRESS: at 60.07% examples, 89046 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:21,374 : INFO : EPOCH 5 - PROGRESS: at 65.30% examples, 89535 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:22,504 : INFO : EPOCH 5 - PROGRESS: at 70.97% examples, 90453 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:23,549 : INFO : EPOCH 5 - PROGRESS: at 76.47% examples, 91691 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:07:24,600 : INFO : EPOCH 5 - PROGRESS: at 80.86% examples, 91008 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:25,680 : INFO : EPOCH 5 - PROGRESS: at 86.62% examples, 91450 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:26,701 : INFO : EPOCH 5 - PROGRESS: at 93.12% examples, 92906 words/s, in_qsize 14, out_qsize 1\n",
      "2020-03-19 17:07:26,944 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:07:26,961 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:07:26,970 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:07:26,987 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:07:26,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:07:26,997 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:07:27,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:07:27,027 : INFO : EPOCH - 5 : training on 2555041 raw words (1989229 effective words) took 20.3s, 97999 effective words/s\n",
      "2020-03-19 17:07:28,606 : INFO : EPOCH 6 - PROGRESS: at 0.75% examples, 9841 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:29,738 : INFO : EPOCH 6 - PROGRESS: at 6.25% examples, 49184 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:30,811 : INFO : EPOCH 6 - PROGRESS: at 11.34% examples, 63624 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:31,875 : INFO : EPOCH 6 - PROGRESS: at 16.75% examples, 72032 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:32,928 : INFO : EPOCH 6 - PROGRESS: at 22.22% examples, 77432 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:33,938 : INFO : EPOCH 6 - PROGRESS: at 27.67% examples, 81767 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:34,970 : INFO : EPOCH 6 - PROGRESS: at 32.81% examples, 83766 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:36,060 : INFO : EPOCH 6 - PROGRESS: at 38.15% examples, 85587 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:37,142 : INFO : EPOCH 6 - PROGRESS: at 43.55% examples, 87109 words/s, in_qsize 13, out_qsize 1\n",
      "2020-03-19 17:07:38,157 : INFO : EPOCH 6 - PROGRESS: at 48.89% examples, 88845 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:39,298 : INFO : EPOCH 6 - PROGRESS: at 54.63% examples, 89985 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:40,298 : INFO : EPOCH 6 - PROGRESS: at 59.65% examples, 90725 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:41,338 : INFO : EPOCH 6 - PROGRESS: at 65.25% examples, 91696 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:42,379 : INFO : EPOCH 6 - PROGRESS: at 70.59% examples, 92517 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:43,422 : INFO : EPOCH 6 - PROGRESS: at 75.33% examples, 92743 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:44,448 : INFO : EPOCH 6 - PROGRESS: at 80.84% examples, 93411 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:45,562 : INFO : EPOCH 6 - PROGRESS: at 86.62% examples, 93558 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:46,562 : INFO : EPOCH 6 - PROGRESS: at 92.72% examples, 94646 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:46,826 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:07:46,836 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:07:46,849 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:07:46,879 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:07:46,880 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:07:46,899 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:07:46,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:07:46,910 : INFO : EPOCH - 6 : training on 2555041 raw words (1989572 effective words) took 19.9s, 100104 effective words/s\n",
      "2020-03-19 17:07:47,931 : INFO : EPOCH 7 - PROGRESS: at 2.81% examples, 53701 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-19 17:07:49,557 : INFO : EPOCH 7 - PROGRESS: at 6.25% examples, 50285 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:50,608 : INFO : EPOCH 7 - PROGRESS: at 10.99% examples, 62909 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:07:51,620 : INFO : EPOCH 7 - PROGRESS: at 16.29% examples, 72363 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:07:52,687 : INFO : EPOCH 7 - PROGRESS: at 21.44% examples, 76397 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:07:53,802 : INFO : EPOCH 7 - PROGRESS: at 26.85% examples, 79707 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:54,835 : INFO : EPOCH 7 - PROGRESS: at 32.41% examples, 82944 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:55,873 : INFO : EPOCH 7 - PROGRESS: at 37.36% examples, 84513 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:07:56,973 : INFO : EPOCH 7 - PROGRESS: at 42.78% examples, 85995 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:07:58,017 : INFO : EPOCH 7 - PROGRESS: at 48.49% examples, 88341 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:07:59,137 : INFO : EPOCH 7 - PROGRESS: at 53.55% examples, 88438 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:00,153 : INFO : EPOCH 7 - PROGRESS: at 58.85% examples, 89794 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:01,314 : INFO : EPOCH 7 - PROGRESS: at 64.51% examples, 90032 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:02,419 : INFO : EPOCH 7 - PROGRESS: at 69.89% examples, 90588 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:03,451 : INFO : EPOCH 7 - PROGRESS: at 75.27% examples, 91918 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:04,460 : INFO : EPOCH 7 - PROGRESS: at 80.07% examples, 91861 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:05,491 : INFO : EPOCH 7 - PROGRESS: at 84.96% examples, 91680 words/s, in_qsize 13, out_qsize 1\n",
      "2020-03-19 17:08:06,501 : INFO : EPOCH 7 - PROGRESS: at 90.09% examples, 92033 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:07,070 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:08:07,084 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:08:07,114 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:08:07,145 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:08:07,153 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:08:07,188 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:08:07,192 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:08:07,192 : INFO : EPOCH - 7 : training on 2555041 raw words (1990125 effective words) took 20.3s, 98133 effective words/s\n",
      "2020-03-19 17:08:08,820 : INFO : EPOCH 8 - PROGRESS: at 1.62% examples, 19239 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:09,834 : INFO : EPOCH 8 - PROGRESS: at 6.95% examples, 56094 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:10,845 : INFO : EPOCH 8 - PROGRESS: at 12.09% examples, 70020 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:08:11,956 : INFO : EPOCH 8 - PROGRESS: at 16.73% examples, 73212 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:13,111 : INFO : EPOCH 8 - PROGRESS: at 23.00% examples, 79746 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:14,147 : INFO : EPOCH 8 - PROGRESS: at 28.06% examples, 82302 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:15,165 : INFO : EPOCH 8 - PROGRESS: at 33.19% examples, 84394 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:16,255 : INFO : EPOCH 8 - PROGRESS: at 37.74% examples, 84435 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:17,269 : INFO : EPOCH 8 - PROGRESS: at 42.78% examples, 85909 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:18,285 : INFO : EPOCH 8 - PROGRESS: at 48.13% examples, 87773 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:19,316 : INFO : EPOCH 8 - PROGRESS: at 52.78% examples, 87919 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:20,387 : INFO : EPOCH 8 - PROGRESS: at 57.73% examples, 88366 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:21,423 : INFO : EPOCH 8 - PROGRESS: at 62.89% examples, 88929 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:22,428 : INFO : EPOCH 8 - PROGRESS: at 67.60% examples, 89161 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:23,534 : INFO : EPOCH 8 - PROGRESS: at 72.42% examples, 89253 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:24,675 : INFO : EPOCH 8 - PROGRESS: at 77.65% examples, 89552 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:25,697 : INFO : EPOCH 8 - PROGRESS: at 82.90% examples, 89974 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:27,008 : INFO : EPOCH 8 - PROGRESS: at 88.90% examples, 89805 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:27,840 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:08:27,860 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:08:27,862 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:08:27,878 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:08:27,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:08:27,917 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:08:27,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:08:27,923 : INFO : EPOCH - 8 : training on 2555041 raw words (1989538 effective words) took 20.7s, 95984 effective words/s\n",
      "2020-03-19 17:08:27,924 : INFO : training on a 20440328 raw words (15916920 effective words) took 162.5s, 97946 effective words/s\n",
      "2020-03-19 17:08:27,924 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-03-19 17:08:27,925 : INFO : training model with 7 workers on 39021 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=8\n",
      "2020-03-19 17:08:28,948 : INFO : EPOCH 1 - PROGRESS: at 2.01% examples, 38268 words/s, in_qsize 1, out_qsize 1\n",
      "2020-03-19 17:08:30,558 : INFO : EPOCH 1 - PROGRESS: at 5.90% examples, 47559 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:31,640 : INFO : EPOCH 1 - PROGRESS: at 10.99% examples, 62549 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:32,674 : INFO : EPOCH 1 - PROGRESS: at 15.88% examples, 70111 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:33,751 : INFO : EPOCH 1 - PROGRESS: at 21.06% examples, 74361 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:34,758 : INFO : EPOCH 1 - PROGRESS: at 26.10% examples, 78089 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:35,830 : INFO : EPOCH 1 - PROGRESS: at 31.25% examples, 80209 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:36,874 : INFO : EPOCH 1 - PROGRESS: at 36.22% examples, 82044 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:37,961 : INFO : EPOCH 1 - PROGRESS: at 41.63% examples, 83891 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:38,988 : INFO : EPOCH 1 - PROGRESS: at 46.67% examples, 85214 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:40,002 : INFO : EPOCH 1 - PROGRESS: at 50.88% examples, 85040 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:41,059 : INFO : EPOCH 1 - PROGRESS: at 55.81% examples, 85806 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:42,079 : INFO : EPOCH 1 - PROGRESS: at 60.82% examples, 86676 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:43,094 : INFO : EPOCH 1 - PROGRESS: at 66.43% examples, 88014 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:44,113 : INFO : EPOCH 1 - PROGRESS: at 71.33% examples, 88655 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:45,124 : INFO : EPOCH 1 - PROGRESS: at 75.65% examples, 88815 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:46,222 : INFO : EPOCH 1 - PROGRESS: at 80.85% examples, 88909 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:47,307 : INFO : EPOCH 1 - PROGRESS: at 86.62% examples, 89444 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:48,330 : INFO : EPOCH 1 - PROGRESS: at 92.30% examples, 90208 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:48,646 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:08:48,657 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:08:48,697 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:08:48,710 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:08:48,711 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:08:48,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:08:48,722 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:08:48,723 : INFO : EPOCH - 1 : training on 2555041 raw words (1989505 effective words) took 20.8s, 95670 effective words/s\n",
      "2020-03-19 17:08:50,244 : INFO : EPOCH 2 - PROGRESS: at 0.76% examples, 10375 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:51,321 : INFO : EPOCH 2 - PROGRESS: at 6.95% examples, 57008 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:08:52,327 : INFO : EPOCH 2 - PROGRESS: at 10.99% examples, 64514 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:53,349 : INFO : EPOCH 2 - PROGRESS: at 15.88% examples, 71960 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:54,367 : INFO : EPOCH 2 - PROGRESS: at 21.01% examples, 76757 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:08:55,461 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 78032 words/s, in_qsize 13, out_qsize 1\n",
      "2020-03-19 17:08:56,556 : INFO : EPOCH 2 - PROGRESS: at 31.24% examples, 80922 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:08:57,575 : INFO : EPOCH 2 - PROGRESS: at 36.62% examples, 83784 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:58,657 : INFO : EPOCH 2 - PROGRESS: at 42.02% examples, 85505 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:08:59,692 : INFO : EPOCH 2 - PROGRESS: at 46.95% examples, 86594 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:09:00,742 : INFO : EPOCH 2 - PROGRESS: at 52.03% examples, 87377 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:09:01,749 : INFO : EPOCH 2 - PROGRESS: at 57.73% examples, 89470 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:02,797 : INFO : EPOCH 2 - PROGRESS: at 62.04% examples, 88809 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:03,825 : INFO : EPOCH 2 - PROGRESS: at 67.94% examples, 90456 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:04,846 : INFO : EPOCH 2 - PROGRESS: at 73.12% examples, 91403 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:05,846 : INFO : EPOCH 2 - PROGRESS: at 78.51% examples, 92331 words/s, in_qsize 9, out_qsize 0\n",
      "2020-03-19 17:09:06,862 : INFO : EPOCH 2 - PROGRESS: at 82.05% examples, 90944 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:09:07,897 : INFO : EPOCH 2 - PROGRESS: at 87.71% examples, 91631 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:09:08,903 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 94660 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:08,943 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:09:08,991 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:09:09,000 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:09:09,048 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:09:09,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:09:09,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:09:09,079 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:09:09,079 : INFO : EPOCH - 2 : training on 2555041 raw words (1989872 effective words) took 20.4s, 97761 effective words/s\n",
      "2020-03-19 17:09:10,170 : INFO : EPOCH 3 - PROGRESS: at 2.43% examples, 43130 words/s, in_qsize 2, out_qsize 0\n",
      "2020-03-19 17:09:11,183 : INFO : EPOCH 3 - PROGRESS: at 3.53% examples, 33566 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:09:12,228 : INFO : EPOCH 3 - PROGRESS: at 8.04% examples, 54263 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:13,309 : INFO : EPOCH 3 - PROGRESS: at 13.18% examples, 65921 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:14,495 : INFO : EPOCH 3 - PROGRESS: at 18.68% examples, 71503 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:15,579 : INFO : EPOCH 3 - PROGRESS: at 24.15% examples, 76175 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:16,663 : INFO : EPOCH 3 - PROGRESS: at 29.62% examples, 79563 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:17,663 : INFO : EPOCH 3 - PROGRESS: at 34.65% examples, 81954 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:18,667 : INFO : EPOCH 3 - PROGRESS: at 39.71% examples, 83819 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:19,692 : INFO : EPOCH 3 - PROGRESS: at 44.34% examples, 84454 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:20,782 : INFO : EPOCH 3 - PROGRESS: at 49.72% examples, 85778 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:21,825 : INFO : EPOCH 3 - PROGRESS: at 55.01% examples, 87197 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:22,932 : INFO : EPOCH 3 - PROGRESS: at 60.44% examples, 87992 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:24,017 : INFO : EPOCH 3 - PROGRESS: at 66.08% examples, 88858 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:25,026 : INFO : EPOCH 3 - PROGRESS: at 70.94% examples, 89521 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:09:26,037 : INFO : EPOCH 3 - PROGRESS: at 76.03% examples, 90504 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:27,044 : INFO : EPOCH 3 - PROGRESS: at 80.48% examples, 90124 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:09:28,112 : INFO : EPOCH 3 - PROGRESS: at 86.18% examples, 90670 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:29,113 : INFO : EPOCH 3 - PROGRESS: at 91.46% examples, 91111 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:29,511 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:09:29,529 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:09:29,531 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:09:29,544 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:09:29,570 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:09:29,575 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:09:29,594 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:09:29,595 : INFO : EPOCH - 3 : training on 2555041 raw words (1989508 effective words) took 20.5s, 96982 effective words/s\n",
      "2020-03-19 17:09:31,280 : INFO : EPOCH 4 - PROGRESS: at 2.04% examples, 23265 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:32,320 : INFO : EPOCH 4 - PROGRESS: at 7.30% examples, 57198 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:33,338 : INFO : EPOCH 4 - PROGRESS: at 11.75% examples, 66258 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:34,385 : INFO : EPOCH 4 - PROGRESS: at 17.14% examples, 74427 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:35,410 : INFO : EPOCH 4 - PROGRESS: at 22.60% examples, 79832 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:36,450 : INFO : EPOCH 4 - PROGRESS: at 27.24% examples, 81285 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:37,571 : INFO : EPOCH 4 - PROGRESS: at 32.81% examples, 83372 words/s, in_qsize 13, out_qsize 1\n",
      "2020-03-19 17:09:38,680 : INFO : EPOCH 4 - PROGRESS: at 38.15% examples, 85066 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:39,729 : INFO : EPOCH 4 - PROGRESS: at 43.55% examples, 86921 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:40,811 : INFO : EPOCH 4 - PROGRESS: at 48.89% examples, 88139 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:41,814 : INFO : EPOCH 4 - PROGRESS: at 53.88% examples, 89103 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:42,841 : INFO : EPOCH 4 - PROGRESS: at 58.48% examples, 89166 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:44,027 : INFO : EPOCH 4 - PROGRESS: at 64.48% examples, 89821 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:09:45,125 : INFO : EPOCH 4 - PROGRESS: at 70.21% examples, 90942 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:46,132 : INFO : EPOCH 4 - PROGRESS: at 75.65% examples, 92374 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:47,223 : INFO : EPOCH 4 - PROGRESS: at 80.43% examples, 91847 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:48,238 : INFO : EPOCH 4 - PROGRESS: at 86.62% examples, 92996 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:49,256 : INFO : EPOCH 4 - PROGRESS: at 90.91% examples, 92467 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:49,719 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:09:49,741 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:09:49,753 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:09:49,812 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:09:49,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:09:49,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:09:49,896 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:09:49,897 : INFO : EPOCH - 4 : training on 2555041 raw words (1989758 effective words) took 20.3s, 98018 effective words/s\n",
      "2020-03-19 17:09:51,462 : INFO : EPOCH 5 - PROGRESS: at 1.62% examples, 20049 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:52,478 : INFO : EPOCH 5 - PROGRESS: at 6.25% examples, 51524 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:09:53,588 : INFO : EPOCH 5 - PROGRESS: at 11.37% examples, 65070 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:54,686 : INFO : EPOCH 5 - PROGRESS: at 16.75% examples, 72814 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:55,786 : INFO : EPOCH 5 - PROGRESS: at 22.22% examples, 77495 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:56,911 : INFO : EPOCH 5 - PROGRESS: at 27.66% examples, 80503 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:57,935 : INFO : EPOCH 5 - PROGRESS: at 33.17% examples, 83686 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:09:58,938 : INFO : EPOCH 5 - PROGRESS: at 38.54% examples, 86298 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:09:59,950 : INFO : EPOCH 5 - PROGRESS: at 42.78% examples, 86068 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:01,038 : INFO : EPOCH 5 - PROGRESS: at 47.77% examples, 86687 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:02,131 : INFO : EPOCH 5 - PROGRESS: at 53.16% examples, 87739 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:03,278 : INFO : EPOCH 5 - PROGRESS: at 58.11% examples, 87685 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:04,317 : INFO : EPOCH 5 - PROGRESS: at 63.30% examples, 88279 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:05,333 : INFO : EPOCH 5 - PROGRESS: at 68.77% examples, 89504 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:06,395 : INFO : EPOCH 5 - PROGRESS: at 73.48% examples, 89813 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:07,513 : INFO : EPOCH 5 - PROGRESS: at 78.93% examples, 90186 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:08,576 : INFO : EPOCH 5 - PROGRESS: at 84.51% examples, 90773 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:09,677 : INFO : EPOCH 5 - PROGRESS: at 90.09% examples, 91135 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:10,221 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:10:10,248 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:10:10,267 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:10:10,321 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:10:10,335 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:10:10,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:10:10,348 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:10:10,349 : INFO : EPOCH - 5 : training on 2555041 raw words (1989483 effective words) took 20.4s, 97299 effective words/s\n",
      "2020-03-19 17:10:11,369 : INFO : EPOCH 6 - PROGRESS: at 3.19% examples, 61461 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-19 17:10:12,465 : INFO : EPOCH 6 - PROGRESS: at 7.66% examples, 77215 words/s, in_qsize 1, out_qsize 0\n",
      "2020-03-19 17:10:14,383 : INFO : EPOCH 6 - PROGRESS: at 13.18% examples, 69103 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:15,390 : INFO : EPOCH 6 - PROGRESS: at 18.29% examples, 75240 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:16,433 : INFO : EPOCH 6 - PROGRESS: at 23.76% examples, 80060 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:17,474 : INFO : EPOCH 6 - PROGRESS: at 29.27% examples, 83587 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:10:18,537 : INFO : EPOCH 6 - PROGRESS: at 33.90% examples, 83997 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:19,604 : INFO : EPOCH 6 - PROGRESS: at 39.73% examples, 86779 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:10:20,740 : INFO : EPOCH 6 - PROGRESS: at 44.73% examples, 86959 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:21,750 : INFO : EPOCH 6 - PROGRESS: at 49.72% examples, 88013 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:22,766 : INFO : EPOCH 6 - PROGRESS: at 55.01% examples, 89469 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:10:23,840 : INFO : EPOCH 6 - PROGRESS: at 60.02% examples, 89745 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:24,842 : INFO : EPOCH 6 - PROGRESS: at 65.26% examples, 90469 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:25,882 : INFO : EPOCH 6 - PROGRESS: at 70.98% examples, 91853 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:10:27,088 : INFO : EPOCH 6 - PROGRESS: at 76.80% examples, 92574 words/s, in_qsize 11, out_qsize 0\n",
      "2020-03-19 17:10:28,116 : INFO : EPOCH 6 - PROGRESS: at 82.46% examples, 93244 words/s, in_qsize 10, out_qsize 0\n",
      "2020-03-19 17:10:29,178 : INFO : EPOCH 6 - PROGRESS: at 87.02% examples, 92444 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:30,180 : INFO : EPOCH 6 - PROGRESS: at 94.52% examples, 94744 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:30,365 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:10:30,388 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:10:30,427 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:10:30,434 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:10:30,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:10:30,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:10:30,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:10:30,481 : INFO : EPOCH - 6 : training on 2555041 raw words (1989126 effective words) took 20.1s, 98814 effective words/s\n",
      "2020-03-19 17:10:31,941 : INFO : EPOCH 7 - PROGRESS: at 0.76% examples, 10791 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:32,975 : INFO : EPOCH 7 - PROGRESS: at 5.90% examples, 50185 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:33,983 : INFO : EPOCH 7 - PROGRESS: at 10.62% examples, 64197 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:34,994 : INFO : EPOCH 7 - PROGRESS: at 15.48% examples, 72103 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:36,042 : INFO : EPOCH 7 - PROGRESS: at 20.30% examples, 75225 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:37,057 : INFO : EPOCH 7 - PROGRESS: at 25.32% examples, 78845 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:38,068 : INFO : EPOCH 7 - PROGRESS: at 30.09% examples, 80586 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:39,075 : INFO : EPOCH 7 - PROGRESS: at 35.44% examples, 83670 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:40,143 : INFO : EPOCH 7 - PROGRESS: at 40.51% examples, 84802 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:41,182 : INFO : EPOCH 7 - PROGRESS: at 45.89% examples, 86670 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:42,231 : INFO : EPOCH 7 - PROGRESS: at 51.28% examples, 88073 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:43,355 : INFO : EPOCH 7 - PROGRESS: at 56.57% examples, 88749 words/s, in_qsize 14, out_qsize 0\n",
      "2020-03-19 17:10:44,390 : INFO : EPOCH 7 - PROGRESS: at 62.04% examples, 89881 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:45,405 : INFO : EPOCH 7 - PROGRESS: at 67.60% examples, 91020 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:46,473 : INFO : EPOCH 7 - PROGRESS: at 73.12% examples, 92174 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:10:47,564 : INFO : EPOCH 7 - PROGRESS: at 78.11% examples, 92098 words/s, in_qsize 13, out_qsize 1\n",
      "2020-03-19 17:10:48,603 : INFO : EPOCH 7 - PROGRESS: at 83.67% examples, 92717 words/s, in_qsize 12, out_qsize 1\n",
      "2020-03-19 17:10:49,703 : INFO : EPOCH 7 - PROGRESS: at 89.64% examples, 93385 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:50,413 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:10:50,425 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:10:50,435 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:10:50,453 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:10:50,472 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:10:50,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:10:50,503 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:10:50,504 : INFO : EPOCH - 7 : training on 2555041 raw words (1989710 effective words) took 20.0s, 99384 effective words/s\n",
      "2020-03-19 17:10:51,601 : INFO : EPOCH 8 - PROGRESS: at 3.19% examples, 57038 words/s, in_qsize 0, out_qsize 0\n",
      "2020-03-19 17:10:52,654 : INFO : EPOCH 8 - PROGRESS: at 8.02% examples, 79440 words/s, in_qsize 1, out_qsize 0\n",
      "2020-03-19 17:10:53,706 : INFO : EPOCH 8 - PROGRESS: at 13.18% examples, 87045 words/s, in_qsize 1, out_qsize 0\n",
      "2020-03-19 17:10:54,740 : INFO : EPOCH 8 - PROGRESS: at 15.09% examples, 74912 words/s, in_qsize 12, out_qsize 0\n",
      "2020-03-19 17:10:55,769 : INFO : EPOCH 8 - PROGRESS: at 19.87% examples, 77893 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:56,791 : INFO : EPOCH 8 - PROGRESS: at 24.95% examples, 81160 words/s, in_qsize 13, out_qsize 1\n",
      "2020-03-19 17:10:57,811 : INFO : EPOCH 8 - PROGRESS: at 30.51% examples, 84677 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:58,822 : INFO : EPOCH 8 - PROGRESS: at 35.44% examples, 86395 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:10:59,862 : INFO : EPOCH 8 - PROGRESS: at 40.87% examples, 88303 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:00,864 : INFO : EPOCH 8 - PROGRESS: at 46.25% examples, 90204 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:01,931 : INFO : EPOCH 8 - PROGRESS: at 51.66% examples, 91186 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:02,948 : INFO : EPOCH 8 - PROGRESS: at 56.57% examples, 91773 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:03,969 : INFO : EPOCH 8 - PROGRESS: at 62.04% examples, 92805 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:05,030 : INFO : EPOCH 8 - PROGRESS: at 67.60% examples, 93473 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:06,283 : INFO : EPOCH 8 - PROGRESS: at 73.48% examples, 93863 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:07,425 : INFO : EPOCH 8 - PROGRESS: at 79.69% examples, 94759 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:08,440 : INFO : EPOCH 8 - PROGRESS: at 84.96% examples, 94931 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:09,447 : INFO : EPOCH 8 - PROGRESS: at 90.06% examples, 95139 words/s, in_qsize 13, out_qsize 0\n",
      "2020-03-19 17:11:10,015 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-19 17:11:10,017 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-19 17:11:10,054 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-19 17:11:10,056 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-19 17:11:10,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-19 17:11:10,109 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-19 17:11:10,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-19 17:11:10,128 : INFO : EPOCH - 8 : training on 2555041 raw words (1989168 effective words) took 19.6s, 101368 effective words/s\n",
      "2020-03-19 17:11:10,129 : INFO : training on a 20440328 raw words (15916130 effective words) took 162.2s, 98124 effective words/s\n",
      "2020-03-19 17:11:10,129 : INFO : saving Doc2Vec object under models\\d2v.model, separately None\n",
      "2020-03-19 17:11:10,130 : INFO : storing np array 'syn1neg' to models\\d2v.model.trainables.syn1neg.npy\n",
      "2020-03-19 17:11:10,603 : INFO : storing np array 'vectors' to models\\d2v.model.wv.vectors.npy\n",
      "2020-03-19 17:11:11,387 : INFO : saved models\\d2v.model\n"
     ]
    }
   ],
   "source": [
    "# COMMENT/UNCOMMENT FOR TRAINING\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "documents = ADTaggedDocument()\n",
    "# model.build_vocab(documents)\n",
    "\n",
    "model = Doc2Vec(documents = documents,\n",
    "                    dm=0, \n",
    "                    dbow_words=1, \n",
    "                    vector_size=300, \n",
    "                    window=8, \n",
    "                    min_count=6, \n",
    "                    epochs=8, \n",
    "                    workers= cores-1\n",
    "#                     alpha=0.06,  # comment these lines to use default alpha\n",
    "#                     min_alpha=0.04\n",
    "                   )\n",
    "\n",
    "# re-initialise generator\n",
    "documents = ADTaggedDocument()\n",
    "# Now train Doc2Vec on the corpus\n",
    "model.train(documents, \n",
    "            total_examples=model.corpus_count, \n",
    "            epochs=model.epochs)\n",
    "\n",
    "\n",
    "model.save(os.path.join('models', 'd2v.model'), separately=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:11:11,393 : INFO : loading Doc2Vec object from models/d2v.model\n",
      "2020-03-19 17:11:11,604 : INFO : loading vocabulary recursively from models/d2v.model.vocabulary.* with mmap=None\n",
      "2020-03-19 17:11:11,605 : INFO : loading trainables recursively from models/d2v.model.trainables.* with mmap=None\n",
      "2020-03-19 17:11:11,606 : INFO : loading syn1neg from models/d2v.model.trainables.syn1neg.npy with mmap=None\n",
      "2020-03-19 17:11:11,644 : INFO : loading wv recursively from models/d2v.model.wv.* with mmap=None\n",
      "2020-03-19 17:11:11,647 : INFO : loading vectors from models/d2v.model.wv.vectors.npy with mmap=None\n",
      "2020-03-19 17:11:11,682 : INFO : loading docvecs recursively from models/d2v.model.docvecs.* with mmap=None\n",
      "2020-03-19 17:11:11,682 : INFO : loaded models/d2v.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x1aae9db0508>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Doc2Vec.load('models/d2v.model')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform our corpus of text data using the doc2vec model to give us a 'd2v_corpus'.  We can visualise this data to get a feel for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.matutils import any2sparse\n",
    "\n",
    "def iter_df(df):\n",
    "    for i, row in df.iterrows():\n",
    "#         doi = str(row['doi'])\n",
    "        id_ = str(row['index'])\n",
    "#             doi = str(row['doi'])\n",
    "        textdata = str(row['tiabs'])\n",
    "        ngrams = pre_d2v_search(textdata, bigram, trigram)\n",
    "        yield id_, ngrams\n",
    "\n",
    "\n",
    "def iter_arts(df):\n",
    "    articles = iter_df(df)\n",
    "    for article in articles:\n",
    "        textdata = article[1]\n",
    "        vec = model.infer_vector(textdata) # can't this be done as a batch/vector process? SLOW!\n",
    "        vec = any2sparse(vec, eps=1e-09)\n",
    "#         print(np.shape(vec))\n",
    "        yield vec\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 17:11:11,773 : INFO : storing corpus in Matrix Market format to data/d2v_corpus.mm\n",
      "2020-03-19 17:11:11,778 : INFO : saving sparse matrix to data/d2v_corpus.mm\n",
      "2020-03-19 17:11:11,786 : INFO : PROGRESS: saving document #0\n",
      "2020-03-19 17:11:16,254 : INFO : PROGRESS: saving document #1000\n",
      "2020-03-19 17:11:20,632 : INFO : PROGRESS: saving document #2000\n",
      "2020-03-19 17:11:24,925 : INFO : PROGRESS: saving document #3000\n",
      "2020-03-19 17:11:29,279 : INFO : PROGRESS: saving document #4000\n",
      "2020-03-19 17:11:33,715 : INFO : PROGRESS: saving document #5000\n",
      "2020-03-19 17:11:38,043 : INFO : PROGRESS: saving document #6000\n",
      "2020-03-19 17:11:42,435 : INFO : PROGRESS: saving document #7000\n",
      "2020-03-19 17:11:46,708 : INFO : PROGRESS: saving document #8000\n",
      "2020-03-19 17:11:51,337 : INFO : PROGRESS: saving document #9000\n",
      "2020-03-19 17:11:55,661 : INFO : PROGRESS: saving document #10000\n",
      "2020-03-19 17:11:59,843 : INFO : PROGRESS: saving document #11000\n",
      "2020-03-19 17:12:03,933 : INFO : PROGRESS: saving document #12000\n",
      "2020-03-19 17:12:06,713 : INFO : saved 12617x300 matrix, density=100.000% (3785100/3785100)\n",
      "2020-03-19 17:12:06,714 : INFO : saving MmCorpus index to data/d2v_corpus.mm.index\n",
      "2020-03-19 17:12:06,716 : INFO : initializing cython corpus reader from data/d2v_train_corpus.mm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 0 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5ed400bb8684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMmCorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/d2v_corpus.mm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_arts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m index_d2v = similarities.Similarity('data/d2v_sims.index',\n\u001b[1;32m----> 4\u001b[1;33m                                       \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMmCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/d2v_train_corpus.mm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                                       num_features=300)\n\u001b[0;32m      6\u001b[0m \u001b[0mindex_d2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adamd\\onedrive\\projects\\coronavirus_pubmed\\venv\\lib\\site-packages\\gensim\\corpora\\mmcorpus.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# avoid calling super(), too confusing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mIndexedCorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMmReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adamd\\onedrive\\projects\\coronavirus_pubmed\\venv\\lib\\site-packages\\gensim\\corpora\\_mmreader.pyx\u001b[0m in \u001b[0;36mgensim.corpora._mmreader.MmReader.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adamd\\onedrive\\projects\\coronavirus_pubmed\\venv\\lib\\site-packages\\gensim\\corpora\\_mmreader.pyx\u001b[0m in \u001b[0;36mgensim.corpora._mmreader.MmReader.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 0 values to unpack"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, similarities\n",
    "transformed = corpora.MmCorpus.serialize('data/d2v_corpus.mm', iter_arts(df))\n",
    "index_d2v = similarities.Similarity('data/d2v_sims.index',\n",
    "                                      corpora.MmCorpus('data/d2v_train_corpus.mm'),\n",
    "                                      num_features=300)\n",
    "index_d2v.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('data/d2v_corpus.mm', iter_arts(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
